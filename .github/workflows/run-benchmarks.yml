name: Run Prime Benchmarks

on:
  workflow_dispatch: # Allows manual triggering of the workflow

permissions:
  contents: write

jobs:
  run-benchmarks:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        language:
          - java_default
          - java_optimized
          - java_graalvm_jvm
          - java_graalvm_native
          - java_graalvm_native_optimized
          - python_default
          - python_pypy
          - python_cython
          - python_nuitka
          - javascript_default
          - javascript_v8_optimized
          - javascript_graalvm
          - cpp_gcc
          - cpp_clang
          - cpp_pgo
          - scala_default
          - c_gcc
          - c_clang
          - csharp_default
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Create results directory
        run: mkdir -p results

      # Set up environments based on language

      # Java setup
      - name: Set up Java (default)
        if: ${{ matrix.language == 'java_default' || matrix.language == 'java_optimized' }}
        uses: actions/setup-java@v3
        with:
          java-version: '21'
          distribution: 'adopt'

      # GraalVM setup
      - name: Set up GraalVM
        if: ${{ startsWith(matrix.language, 'java_graalvm') || matrix.language == 'javascript_graalvm' }}
        uses: graalvm/setup-graalvm@v1
        with:
          java-version: '21'
          distribution: 'graalvm'
          components: 'native-image,nodejs'

      # Scala setup
      - name: Install Scala
        if: ${{ matrix.language == 'scala_default' }}
        run: |
          sudo apt-get update
          sudo apt-get install -y scala

      # Node.js setup
      - name: Set up Node.js
        if: ${{ matrix.language == 'javascript_default' || matrix.language == 'javascript_v8_optimized' }}
        uses: actions/setup-node@v3
        with:
          node-version: '20'

      # C and C++ setup
      - name: Install GCC
        if: ${{ matrix.language == 'cpp_gcc' || matrix.language == 'cpp_pgo' || matrix.language == 'c_gcc' }}
        run: sudo apt-get update && sudo apt-get install -y gcc g++

      - name: Install Clang
        if: ${{ matrix.language == 'cpp_clang' || matrix.language == 'c_clang' }}
        run: sudo apt-get update && sudo apt-get install -y clang

      # Python setup
      - name: Set up Python
        if: ${{ matrix.language == 'python_default' || matrix.language == 'python_cython' || matrix.language == 'python_nuitka' }}
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'

      # PyPy setup
      - name: Set up PyPy
        if: ${{ matrix.language == 'python_pypy' }}
        uses: actions/setup-python@v4
        with:
          python-version: 'pypy-3.9'

      # Cython installation
      - name: Install Cython
        if: ${{ matrix.language == 'python_cython' }}
        run: pip install cython

      # Nuitka installation
      - name: Install Nuitka
        if: ${{ matrix.language == 'python_nuitka' }}
        run: pip install nuitka

      # .NET SDK setup for C#
      - name: Set up .NET SDK
        if: ${{ matrix.language == 'csharp_default' }}
        uses: actions/setup-dotnet@v3
        with:
          dotnet-version: '7.0.x' # Use the latest .NET 7 SDK

      # Benchmark Execution
      - name: Run Benchmark
        continue-on-error: true
        env:
          GRAALVM_HOME: ${{ steps.setup-graalvm.outputs.GRAALVM_HOME }}
          PATH: ${{ steps.setup-graalvm.outputs.GRAALVM_HOME }}/bin:${{ env.PATH }}
        run: |
          # Java default benchmark
          if [ "${{ matrix.language }}" == "java_default" ]; then
            cd benchmarks/java
            javac PrimeBenchmark.java
            java PrimeBenchmark > ../../results/java_result.json
          fi

          # Java optimized benchmark with JVM flags
          if [ "${{ matrix.language }}" == "java_optimized" ]; then
            cd benchmarks/java
            javac PrimeBenchmark.java
            java -XX:+UnlockExperimentalVMOptions -XX:+UseG1GC -XX:+UseStringDeduplication PrimeBenchmark > ../../results/java_optimized_result.json
          fi

          # Java benchmark with GraalVM JVM
          if [ "${{ matrix.language }}" == "java_graalvm_jvm" ]; then
            cd benchmarks/java
            javac PrimeBenchmark.java
            java PrimeBenchmark > ../../results/java_graalvm_jvm_result.json
          fi

          # Java benchmark with GraalVM Native Image
          if [ "${{ matrix.language }}" == "java_graalvm_native" ]; then
            cd benchmarks/java
            javac PrimeBenchmark.java
            native-image --no-fallback PrimeBenchmark
            cd ../../
            ./benchmarks/java/primebenchmark > results/java_graalvm_native_result.json
          fi

          # Java benchmark with optimized GraalVM Native Image
          if [ "${{ matrix.language }}" == "java_graalvm_native_optimized" ]; then
            cd benchmarks/java
            javac PrimeBenchmark.java
            # Generate profile data
            native-image --no-fallback --pgo-instrument PrimeBenchmark
            ./primebenchmark
            # Use profile data for optimization
            native-image --no-fallback --pgo=default.iprof PrimeBenchmark
            cd ../../
            ./benchmarks/java/primebenchmark > results/java_graalvm_native_optimized_result.json
          fi

          # Python default benchmark
          if [ "${{ matrix.language }}" == "python_default" ]; then
            python3 benchmarks/python/prime_benchmark.py > results/python_result.json
          fi

          # Python benchmark with PyPy
          if [ "${{ matrix.language }}" == "python_pypy" ]; then
            python benchmarks/python/prime_benchmark.py > results/python_pypy_result.json
          fi

          # Python benchmark compiled with Cython
          if [ "${{ matrix.language }}" == "python_cython" ]; then
            cython benchmarks/python/prime_benchmark.py --embed -o benchmarks/python/prime_benchmark.c
            gcc -Os -I $(python3-config --includes) -o benchmarks/python/prime_benchmark benchmarks/python/prime_benchmark.c $(python3-config --ldflags)
            ./benchmarks/python/prime_benchmark > results/python_cython_result.json
          fi

          # Python benchmark compiled with Nuitka
          if [ "${{ matrix.language }}" == "python_nuitka" ]; then
            nuitka --onefile benchmarks/python/prime_benchmark.py
            ./prime_benchmark.bin > results/python_nuitka_result.json
          fi

          # JavaScript default benchmark
          if [ "${{ matrix.language }}" == "javascript_default" ]; then
            node benchmarks/js/prime_benchmark.js > results/js_result.json
          fi

          # JavaScript benchmark with V8 optimization flags
          if [ "${{ matrix.language }}" == "javascript_v8_optimized" ]; then
            node --turbo --optimize_for_size --max-old-space-size=4096 benchmarks/js/prime_benchmark.js > results/js_v8_optimized_result.json
          fi

          # JavaScript benchmark with GraalVM
          if [ "${{ matrix.language }}" == "javascript_graalvm" ]; then
            js benchmarks/js/prime_benchmark.js > results/js_graalvm_result.json
          fi

          # C++ benchmark compiled with GCC
          if [ "${{ matrix.language }}" == "cpp_gcc" ]; then
            g++ -O3 -march=native -flto -o benchmarks/cpp/PrimeBenchmark benchmarks/cpp/PrimeBenchmark.cpp
            ./benchmarks/cpp/PrimeBenchmark > results/cpp_result.json
          fi

          # C++ benchmark compiled with Clang
          if [ "${{ matrix.language }}" == "cpp_clang" ]; then
            clang++ -O3 -march=native -flto -o benchmarks/cpp/PrimeBenchmark benchmarks/cpp/PrimeBenchmark.cpp
            ./benchmarks/cpp/PrimeBenchmark > results/cpp_clang_result.json
          fi

          # C++ benchmark with PGO
          if [ "${{ matrix.language }}" == "cpp_pgo" ]; then
            # Compile with instrumentation
            g++ -O3 -march=native -fprofile-generate -o benchmarks/cpp/PrimeBenchmark_PGO benchmarks/cpp/PrimeBenchmark.cpp
            # Run to generate profile data
            ./benchmarks/cpp/PrimeBenchmark_PGO
            # Compile using profile data
            g++ -O3 -march=native -fprofile-use -fprofile-correction -o benchmarks/cpp/PrimeBenchmark_PGO benchmarks/cpp/PrimeBenchmark.cpp
            ./benchmarks/cpp/PrimeBenchmark_PGO > results/cpp_pgo_result.json
          fi

          # Scala benchmark
          if [ "${{ matrix.language }}" == "scala_default" ]; then
            cd benchmarks/scala
            scalac PrimeBenchmark.scala
            scala PrimeBenchmark > ../../results/scala_result.json
          fi

          # C benchmark compiled with GCC
          if [ "${{ matrix.language }}" == "c_gcc" ]; then
            gcc -O3 -march=native -flto -o benchmarks/c/PrimeBenchmark benchmarks/c/PrimeBenchmark.c
            ./benchmarks/c/PrimeBenchmark > results/c_gcc_result.json
          fi

          # C benchmark compiled with Clang
          if [ "${{ matrix.language }}" == "c_clang" ]; then
            clang -O3 -march=native -flto -o benchmarks/c/PrimeBenchmark benchmarks/c/PrimeBenchmark.c
            ./benchmarks/c/PrimeBenchmark > results/c_clang_result.json
          fi

          # C# benchmark
          if [ "${{ matrix.language }}" == "csharp_default" ]; then
            cd benchmarks/csharp
            dotnet build -c Release
            dotnet run -c Release > ../../results/csharp_result.json
          fi

      - name: Upload Result Artifact
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: ${{ matrix.language }}-results
          path: results/

  generate-report:
    runs-on: ubuntu-latest
    needs: run-benchmarks
    if: always()
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Download Artifacts
        uses: actions/download-artifact@v3
        with:
          path: results

      - name: List Downloaded Artifacts
        run: |
          ls -R results

      - name: Generate Markdown Report
        run: |
          javac MarkdownGenerator.java
          java MarkdownGenerator

      - name: Commit results
        run: |
          git config --global user.name "GitHub Actions Bot"
          git config --global user.email "actions@github.com"
          git add results_summary.md
          git commit -m "Update benchmark results"
          git push